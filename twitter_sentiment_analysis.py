# -*- coding: utf-8 -*-
"""Twitter Sentiment Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xv9h-bNvtxh2Fe5dknXUpCrjkwsDU94r
"""

pip install git+https://github.com/JustAnotherArchivist/snscrape.git

pip install yfinance

pip install nltk

pip install wordcloud

pip install textblob

pip install vaderSentiment

import snscrape.modules.twitter as sntwitter
import yfinance as yf
import pandas as pd
import matplotlib as plt

import sys
import re         # Imports regular expression operations
import string     # For string operations
import json
import os

import nltk
nltk.download('vader_lexicon')
nltk.download('wordnet')
nltk.download('stopwords')
nltk.download('punkt')
from nltk.corpus import stopwords            # module for stop words that come with nltk
from nltk.tokenize import word_tokenize      # module for tokenizing strings

from nltk.sentiment.vader import SentimentIntensityAnalyzer
import unicodedata
sentiment_i_a = SentimentIntensityAnalyzer()

from nltk.corpus import subjectivity
from nltk.sentiment import SentimentAnalyzer
from nltk.sentiment.util import *

from wordcloud import WordCloud

import config      #python file with API credentials for authentication

import tweepy
import requests
import matplotlib.pyplot as plt
import json
import boto3
import datetime
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import csv

#Get stock data for the given Stock Name
def getStockDetails(stockname, start_time, end_time):
    company = yf.Ticker(stockname)
    company.info.get("longName")
    stockData = yf.download(stockname, start=start_time, end=end_time)
    print("\n Stock Data Obtained ")
    print(stockData.head())
    print("\n")
    f = plt.figure()
    f.set_figwidth(12)
    f.set_figheight(5)
    plt.title('Time series chart of Closing stocks for ' + company.info.get("longName"))
    plt.plot(stockData["Close"])
    plt.show()
    print("\n")
    stockData.to_csv('stockData_' + stockname + '.csv')

def cleanTweets(text):
    text = re.sub(r'@[A-Za-z0-9]+', '', text) # removes @ mentions
    text = re.sub(r'#', '', text) # removes '#' symbol
    text = re.sub(r'RT[\s]+', '', text) # removing Retweet
    text = re.sub(r'https?:\/\/\S+', '', text) # removes hyperlink

    return text

def getTweets(stockname, query, limit):
    # Creating list to append tweet data to
    tweets = []

    # Using TwitterSearchScraper to scrape data and append tweets to list
    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):
        if i>limit:
            break
        tweets.append([tweet.date, tweet.id, tweet.content, tweet.user.username])

    # Creating a dataframe from the tweets list above
    tweets_df = pd.DataFrame(tweets, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])
    return tweets_df

#print(getTweets('msft until:2022-01-01 since:2021-01-03').to_string())

# Display both stock and twitter data
name = input("Enter a valid STOCKNAME of the Corporation: ") #enter the name of the company
start_date = input("Enter the Start Date in the following format[YYYY-MM-DD]: ") #enter the start date to fetch the tweets
end_date = input("Enter the End Date in the following format[YYYY-MM-DD]: " ) #enter the end date to fetch the tweets

if(len(name) > 0):
    STOCKNAME  = name
else:
    STOCKNAME = "AAPL"

if(len(start_date) > 0):
    start_time = start_date
else:
    start_time = "2018-01-01"

if(len(end_date) > 0):
    end_time = end_date
else:
    end_time = "2019-12-31"


#Get Stock Details
print("------------------------------ Getting Stock details -----------------------------")
stockData = getStockDetails(STOCKNAME, start_time, end_time)
print("\n")

#Get Tweets
print("------------------------------ Getting Tweets -----------------------------")
query = STOCKNAME + ' lang:en' + ' since:' + start_time +' until:' + end_time  # example - microsoft until:2022-01-01 since:2021-01-03
tweetData = getTweets(STOCKNAME, query, 100)
print(tweetData)

tweetData.head()

from textblob import TextBlob
from textblob import Word
# Lower casing and removing punctuations

tweetData['Text'] = tweetData['Text'].apply(lambda x: " ".join(x.lower() for
x in x.split()))
tweetData['Text'] = tweetData['Text'].str.replace('[^\w\s]', "")
tweetData.Text.head()

from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

def word_cloud(wd_list):
    stopwords = set(STOPWORDS)
    new_stopwords = ['https', 'co', 'QQQ', 'elonmusk', 'Tesla', 'TSLA', 't']
    stopwords.update(new_stopwords)
    new_stopwords_list = set(stopwords)
    all_words = ' '.join([text for text in wd_list])
    wordcloud = WordCloud(
        background_color='black',
        stopwords=new_stopwords_list,
        width=1600,
        height=800,
        random_state=1,
        colormap='jet',
        max_words=80,
        max_font_size=200).generate(all_words)
    plt.figure(figsize=(12, 10))
    plt.axis('off')
    plt.imshow(wordcloud, interpolation="bilinear");
word_cloud(tweetData['Text'])

# Adding stock terms to vader to improve sentiment analysis, score: 4.0 to -4.0
new_words = {
    'citron': -4.0,
    'hidenburg': -4.0,
    'moon': 4.0,
    'highs': 2.0,
    'mooning': 4.0,
    'long': 2.0,
    'short': -2.0,
    'call': 4.0,
    'calls': 4.0,
    'put': -4.0,
    'puts': -4.0,
    'break': 2.0,
    'tendie': 2.0,
     'tendies': 2.0,
     'town': 2.0,
     'overvalued': -3.0,
     'undervalued': 3.0,
     'buy': 4.0,
     'sell': -4.0,
     'gone': -1.0,
     'gtfo': -1.7,
     'paper': -1.7,
     'bullish': 3.7,
     'bearish': -3.7,
     'bagholder': -1.7,
     'stonk': 1.9,
     'green': 1.9,
     'money': 1.2,
     'print': 2.2,
     'rocket': 2.2,
     'bull': 2.9,
     'bear': -2.9,
     'pumping': -1.0,
     'sus': -3.0,
     'offering': -2.3,
     'rip': -4.0,
     'downgrade': -3.0,
     'upgrade': 3.0,
     'maintain': 1.0,
     'pump': 1.9,
     'hot': 1.5,
     'drop': -2.5,
     'rebound': 1.5,
     'crack': 2.5,}

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
analyzer = SentimentIntensityAnalyzer()

analyzer.lexicon.update(new_words)

tweetData.head(50)

# Generating sentiment for all the sentence present in the dataset
emptyline=[]
for tweet in tweetData['Text']:
    scores=analyzer.polarity_scores(tweet)
    emptyline.append(scores)
# Creating new dataframe with sentiments
df_sentiments=pd.DataFrame(emptyline)
df_sentiments.head(20)

# Merging the sentiments back to tweet dataframe
df_t = pd.concat([tweetData.reset_index(drop=True), df_sentiments], axis=1)
df_t.head()

# Convert scores into positive, negetive, and neutral sentiments using some threshold
df_t['Sentiment'] = np.where(df_t['compound'] >= 0 , 'Positive','Negative')
for i, compound_val in enumerate(df_t['compound']):
    if compound_val == 0:
        df_t['Sentiment'][i] = 'Neutral'

df_t.head(50)

df_t['Text'][106]

result=df_t['Sentiment'].value_counts()
result.plot(kind='bar', rot=0, color=['plum','cyan', 'red']);

# Split Datetime into Date and Time
import datetime
df_t['Time'],df_t['Date']= df_t['Datetime'].apply(lambda x:x.time()), df_t['Datetime'].apply(lambda x:x.date())

# Reset index without removing default index
stockData.reset_index(inplace = True)

for i, date in enumerate(stockData['Date']):
    if date == df_t['Date'][i]:
        df_t['Close'] = stockData['Close'][i]

df_t = df_t[['Date', 'Time', 'Datetime', 'Text', 'compound', 'Sentiment', 'Close']]

df_t

stockData

sentiment_scores = []
df_t['Hour'] = df_t['Datetime'].dt.round('H').dt.hour
#sentiment_scores = df_t.groupby(pd.Grouper(level='Time', freq='H')).mean()
sentiment_scores = df_t.groupby(['Date', 'Hour'], as_index= False)['compound'].mean()

df = pd.DataFrame(sentiment_scores)
compound = []
compound = [x*20 for x in df['compound']]
df.head(30)

df_t

df_graph=df_t[['Datetime', 'Close', 'compound']]
#df_graph['sentiment score']=sentiment_scores
df_graph=df_graph.set_index('Datetime')
#df_graph=df_graph[df_graph['Close'].notna()]

df_graph

df.head()

# plot the sentiment data
sns.set(
    rc={'figure.figsize':(12,5)},
    style="darkgrid" # nicer layout
)
# and the tesla stock price
sns.lineplot(x=stockData['Date'], y=stockData['Close'])
sns.lineplot(secondary_y = sentiment)

fig, ax1 = plt.subplots(figsize=(12,6))

ax2 = ax1.twinx()
ax1.plot(stockData['Date'], stockData['Close'])
ax2.plot(stockData['Date'], stockData['compound'], color="red" )

ax1.set_xlabel('Date')
ax1.set_ylabel('Price $', color='b')
ax2.set_ylabel('Sentiment Score', color='r')

plt.show()

# Smooth out the sentiment score using a fourier transform
close_fft = np.fft.fft(np.asarray(df['compound'].tolist()))
fft_df = pd.DataFrame({'fft':close_fft})
fft_df['absolute'] = fft_df['fft'].apply(lambda x: np.abs(x))
fft_df['angle'] = fft_df['fft'].apply(lambda x: np.angle(x))
fft_list = np.asarray(fft_df['fft'].tolist())

for num_ in [5, 10, 15, 20]:
    fft_list_m10= np.copy(fft_list); fft_list_m10[num_:-num_]=0
    df['fourier '+str(num_)]=np.fft.ifft(fft_list_m10)

df[['compound']].plot(figsize=(16, 10));

fig, ax1 = plt.subplots(figsize=(12,6))

ax2 = ax1.twinx()
ax1.plot(stockData['Date'], stockData['Close'])
ax2.plot(stockData['Date'], stockData['fourier 20'], color="red" )

ax1.set_xlabel('Date')
ax1.set_ylabel('Price $', color='b')
ax2.set_ylabel('Sentiment Score', color='r')

plt.show()

stockData['fourier 20'] = df['fourier 20']
stockData['compound'] = df['compound']
stockData['fourier 10'] = df['fourier 10']
stockData['fourier 15'] = df['fourier 15']

stockData[['Close', 'fourier 20']].plot(secondary_y='fourier 20', figsize=(16, 10));

stockData =
stockData[['Close', 'compound']].plot(secondary_y='compound', figsize=(16, 10));

df[['fourier 20']].plot(figsize=(16, 10));

df